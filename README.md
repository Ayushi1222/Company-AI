# Conversational Company Research Assistant & Account Plan Generator

## ğŸ¯ Overview

An intelligent, conversational Streamlit application that conducts comprehensive company research and generates actionable account plans through natural dialogue. This agent prioritizes user experience, transparency, and adaptability across diverse interaction patterns.

## ğŸŒŸ Key Features

### 1. **Conversational Agent Interface**
- **Multi-turn dialogue**: Natural conversation flow with context retention
- **Persistent state**: Conversation history maintained via Streamlit session_state
- **Adaptive responses**: Agent adjusts to user style (confused, efficient, chatty, edge-case)

### 2. **Comprehensive Data Research**
The agent aggregates company intelligence from multiple sources:

- **Web Scraping**: Custom Scrapy spiders for company websites, news articles, and public data
- **News APIs**: Real-time headlines via NewsAPI/GNews
- **Company Enrichment**: Hunter.io API for email patterns and org data (FREE: 25/month)
- **Brand Information**: Brandfetch API for logos, colors, social links (FREE: 100/month)
- **Legal Registry**: OpenCorporates for official company information
- **Document Parsing**: Extract insights from uploaded PDFs/documents
- **LinkedIn Data**: Public profile information (respecting ToS)

### 3. **Intelligent Account Plan Generation**
Automatically generates and organizes:
- **Company Overview**: Mission, products, market position
- **Leadership Team**: Key executives and decision-makers
- **Financials**: Revenue, funding, growth metrics
- **SWOT Analysis**: Strengths, weaknesses, opportunities, threats
- **Opportunities**: Strategic engagement points
- **Risk Assessment**: Potential challenges and mitigation

### 4. **Transparency & Agentic Behavior**
- **Real-time status updates**: "Researching company news...", "Analyzing financials..."
- **Conflict resolution**: "Found two different revenue figuresâ€”would you like me to investigate further?"
- **Proactive suggestions**: "I notice this is a SaaS company. Should I focus on recurring revenue metrics?"
- **Editable sections**: Users can correct, update, or regenerate any part of the plan

### 5. **Export & Sharing**
- **Multiple formats**: PDF, Word (DOCX)
- **Professional formatting**: Clean, business-ready output
- **Optional**: Shareable links, email distribution

### 6. **Accessibility Features**
- **Text-to-Speech**: Read sections aloud via gTTS/pyttsx3
- **Voice input**: (Future enhancement)
- **Keyboard navigation**: Full accessibility support

### 7. **Robust Error Handling**
- API timeout recovery
- Invalid input validation with helpful prompts
- Graceful degradation when sources are unavailable
- Clear, actionable error messages

## ğŸ—ï¸ Architecture & Design Decisions

### Technology Stack

**Frontend/UI: Streamlit**
- *Why*: Rapid development, native Python integration, excellent for conversational UIs
- *Tradeoff*: Less control than React but faster iteration for data apps

**Scraping: Scrapy**
- *Why*: Industrial-strength, respects robots.txt, excellent for modular multi-source scraping
- *Tradeoff*: Steeper learning curve than BeautifulSoup but better for production

**APIs: NewsAPI, Hunter.io, Brandfetch, OpenCorporates**
- *Why*: All offer genuine FREE tiers (not just trials) - Hunter (25/mo), Brandfetch (100/mo)
- *Tradeoff*: Rate limits require intelligent caching and fallback strategies
- *Alternative to Clearbit*: Hunter.io provides domain/email data, Brandfetch provides brand assets

**AI: OpenAI GPT (Optional)**
- *Why*: High-quality summarization and analysis
- *Tradeoff*: Cost per request; fallback to rule-based summaries available

**Export: python-docx, ReportLab**
- *Why*: Native Python libraries for professional document generation
- *Tradeoff*: Complex formatting requires more code than templates

**Database: SQLite**
- *Why*: Zero-config, perfect for local drafts and history
- *Tradeoff*: Not suitable for multi-user production (upgrade to PostgreSQL if needed)

### Conversation Management Strategy

The agent employs a **state-machine approach** with conversational memory:

1. **Context Tracking**: Maintains user intent, mentioned companies, and clarification needs
2. **Turn Management**: Detects questions, commands, confirmations, and tangents
3. **Adaptive Response**: Matches user communication style:
   - **Confused users**: Ask clarifying questions, provide examples
   - **Efficient users**: Direct answers, minimal fluff
   - **Chatty users**: Engage naturally, track topic changes
   - **Edge cases**: Validate inputs, suggest alternatives

4. **Transparency Loop**:
   ```
   User Request â†’ Agent Acknowledgment â†’ Status Updates â†’ Results â†’ Verification
   ```

### Edge Case Handling

**Scenario: Ambiguous Company Name**
- Agent asks: "I found 3 companies named 'Apple'. Did you mean Apple Inc. (tech), Apple Records (music), or Apple Bank?"

**Scenario: API Failure**
- Agent notifies: "NewsAPI is temporarily unavailable. I'll proceed with web scraping and cached data."

**Scenario: Conflicting Data**
- Agent presents: "Source A says $500M revenue; Source B says $450M. Would you like me to prioritize the more recent source?"

**Scenario: Out-of-Scope Request**
- Agent responds: "I specialize in company research. For personal profiles, I recommend LinkedIn directly."

## ğŸ§ª Testing & Demo Scenarios

### Test Persona 1: Confused User
```
User: "um i need info on that tech company"
Agent: "I'd be happy to help! Could you tell me the company name? For example, 'Microsoft' or 'Salesforce'."
User: "the one that makes iphones"
Agent: "Got it! You're looking for Apple Inc. Let me gather comprehensive information..."
```

### Test Persona 2: Efficient User
```
User: "Research Stripe, focus on recent funding and competitive position"
Agent: "Researching Stripe - prioritizing funding data and competitive analysis. One moment..."
[Returns structured data in 30 seconds]
```

### Test Persona 3: Chatty User
```
User: "Hey! So I'm thinking about Shopify, they're pretty cool right? My friend works there actually..."
Agent: "Shopify is indeed impressive! Let me pull together their latest company data. Should I include info about their workplace culture since you have a connection there?"
```

### Test Persona 4: Edge Case User
```
User: [Pastes 5000 word essay]
Agent: "I received a large input. Could you summarize what you need in a sentence or two? For example: 'Research [Company] and focus on [specific areas]'."

User: "Analyze xyzzqwert123"
Agent: "I couldn't find a company named 'xyzzqwert123'. Could you double-check the spelling or provide more context?"
```

## ğŸ“¦ Installation & Setup

### 1. Clone and Setup Environment
```bash
# Navigate to project directory
cd "d:\Company AI"

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows PowerShell:
.\venv\Scripts\Activate.ps1
# Windows CMD:
.\venv\Scripts\activate.bat
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure API Keys
```bash
# Copy template
cp .env.template .env

# Edit .env with your actual API keys
notepad .env  # Windows
nano .env     # Linux/Mac
```

### 3. Run the Application
```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

## ğŸ”§ Configuration

### API Keys (in .env)
- **NewsAPI**: Get free key at https://newsapi.org/ (100 requests/day)
- **Hunter.io**: Get free key at https://hunter.io/ (25 searches/month) 
- **Brandfetch**: Get free key at https://brandfetch.com/ (100 requests/month)
- **OpenAI**: Optional, for AI-powered summaries
- **OpenCorporates**: Optional, for legal entity data

### Scraping Settings
Edit `config/scraper_config.py`:
```python
RESPECT_ROBOTS_TXT = True
DOWNLOAD_DELAY = 2  # seconds between requests
CONCURRENT_REQUESTS = 8
USER_AGENT = "Your custom user agent"
```

## ğŸ“ Project Structure

```
Company AI/
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .env.template                   # API key template
â”œâ”€â”€ .env                           # Actual API keys (gitignored)
â”œâ”€â”€ README.md                       # This file
â”‚
â”œâ”€â”€ agents/                         # Conversational agent logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conversation_manager.py    # Dialogue flow and state management
â”‚   â”œâ”€â”€ persona_detector.py        # Detect user communication style
â”‚   â””â”€â”€ response_generator.py      # Generate adaptive responses
â”‚
â”œâ”€â”€ research/                       # Data collection modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ news_api.py                # NewsAPI/GNews integration
â”‚   â”œâ”€â”€ clearbit_api.py            # Clearbit enrichment
â”‚   â”œâ”€â”€ opencorporates_api.py      # Company registry data
â”‚   â”œâ”€â”€ pdf_parser.py              # Document extraction
â”‚   â””â”€â”€ data_aggregator.py         # Combine all sources
â”‚
â”œâ”€â”€ scrapers/                       # Scrapy spiders
â”‚   â”œâ”€â”€ scrapy.cfg
â”‚   â”œâ”€â”€ spiders/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ company_spider.py      # Main company website scraper
â”‚   â”‚   â”œâ”€â”€ news_spider.py         # News article scraper
â”‚   â”‚   â””â”€â”€ linkedin_spider.py     # LinkedIn public data
â”‚   â””â”€â”€ pipelines.py               # Data processing pipelines
â”‚
â”œâ”€â”€ account_plan/                   # Plan generation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ generator.py               # Plan structure and logic
â”‚   â”œâ”€â”€ sections.py                # Individual section generators
â”‚   â””â”€â”€ templates.py               # Output templates
â”‚
â”œâ”€â”€ export/                         # Document export
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pdf_exporter.py            # PDF generation
â”‚   â””â”€â”€ docx_exporter.py           # Word document generation
â”‚
â”œâ”€â”€ database/                       # Local storage
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py                  # SQLAlchemy models
â”‚   â””â”€â”€ crud.py                    # Database operations
â”‚
â”œâ”€â”€ utils/                          # Utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ validators.py              # Input validation
â”‚   â”œâ”€â”€ error_handlers.py          # Error handling
â”‚   â””â”€â”€ tts.py                     # Text-to-speech
â”‚
â””â”€â”€ config/                         # Configuration
    â”œâ”€â”€ __init__.py
    â””â”€â”€ settings.py                # App settings
```

## ğŸ¨ UI Components

### Chat Interface
- Message bubbles with timestamps
- User vs. Agent message distinction
- Status indicators (typing, processing, error)

### Account Plan Tabs
1. **Overview**: Company basics
2. **Team**: Leadership profiles
3. **Financials**: Revenue, funding, metrics
4. **SWOT**: Analysis framework
5. **Opportunities**: Sales/partnership angles
6. **Risks**: Challenges and mitigation

### Interactive Elements
- File uploader for PDFs
- Editable text areas for each section
- Regenerate buttons
- Export dropdown
- TTS playback controls

## ğŸ”’ Best Practices & Ethics

### Web Scraping
- âœ… Respect robots.txt
- âœ… Rate limiting (2-3 seconds between requests)
- âœ… Identify with proper User-Agent
- âœ… Cache results to minimize requests
- âŒ Never scrape personal data without consent
- âŒ Don't overwhelm servers

### API Usage
- Implement exponential backoff on failures
- Cache responses when possible
- Monitor rate limits
- Provide fallback data sources

### Data Privacy
- Don't store sensitive user inputs long-term
- Encrypt API keys
- Allow users to delete their data
- Be transparent about data sources

## ğŸš€ Future Enhancements

- [ ] Multi-language support
- [ ] Voice input via Web Speech API
- [ ] Collaboration features (shared plans)
- [ ] Advanced analytics dashboard
- [ ] Integration with CRM systems (Salesforce, HubSpot)
- [ ] Email/Slack notifications
- [ ] Custom scraping templates per industry
- [ ] A/B testing different conversation strategies

## ğŸ› Troubleshooting

### "Module not found" errors
```bash
pip install -r requirements.txt --upgrade
```

### Scrapy SSL errors
```bash
pip install 'scrapy[ssl]'
```

### Streamlit not loading
```bash
streamlit cache clear
```

### API rate limits
- Check your API key quotas
- Increase SCRAPING_DELAY in .env
- Consider upgrading API plans

## ğŸ“Š Analytics & Monitoring

The app tracks (stored locally in SQLite):
- Number of companies researched
- Most popular sections viewed
- Export frequency by format
- Average conversation length
- User satisfaction ratings

Access analytics via the "Analytics" tab in the sidebar.

## ğŸ“ License

MIT License - Feel free to use and modify for your needs.

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Submit a pull request

## ğŸ“ Support

For issues or questions:
- Open a GitHub issue
- Check the FAQ in the app sidebar
- Review test scenarios in this README

---

**Built with â¤ï¸ for intelligent company research and account planning**
